## Hi there ðŸ‘‹
I enjoy building AI applications that solve real problems using clean engineering and modern LLMs.
I am an AI/ML Engineer passionate about building intelligent systems using Python, Deep Learning, and Generative AI.
My expertise spans the full AI lifecycle from understanding core ML algorithms and Neural Networks to architecting advanced RAG pipelines and Agentic workflows. I focus on bridging the gap between data science and software engineering, transforming raw data into reliable, production-ready applications.

Few examples of What I Build :
RAG Systems-
Engineered a YouTube Intelligence Agent using LangChain and ChromaDB that enables grounded Q&A over video transcripts while significantly reducing hallucinations.
Multi-API Orchestration-
Built Morning Buddy, an AI-driven daily planner that orchestrates Weather, News, and Events APIs to autonomously generate structured Morning, Afternoon, Evening itineraries.
Multimodal Pipelines-
Developed storytelling systems using Gemini Flash that combine images and text into coherent narratives, with real-time audio narration.

What I Bring:
Generative AI Expertise: Specialized in architecting RAG pipelines and Agentic Workflows, utilizing LangChain, LangGraph, Google Gemini, and HuggingFace to build grounded, hallucination-free AI applications.
Data Engineering & Automation: Strong background in designing robust multi-API data pipelines and optimizing backend workflows for high-performance systems using Python and FastAPI.
Database Proficiency: Skilled in working with Relational databases (PostgreSQL, MySQL), NoSQL (MongoDB), and specialized Vector Databases (ChromaDB) for semantic search.
Cloud & Deployment: Experience in deploying scalable AI solutions on AWS (EC2, Lambda) and containerizing applications with Docker for consistent production environments.

Technical Stack:
GenAI & LLMs: LangChain, LangGraph, RAG, Google Gemini API, OpenAI API, HuggingFace
ML & Data: NLP, PyTorch, Scikit-learn, Pandas, NumPy
Backend & Cloud: Python, FastAPI, Docker, AWS (EC2, Lambda), SQL, Git

Professional Impact
During my internships at TTK Services and AdOpsGuy, I focused on building AI-powered research workflows:
Reduced manual research effort by ~40% through Python automation and AI-assisted data processing
Processed 50+ datasets weekly with consistent accuracy using structured AI pipelines
Designed prompt strategies that produced structured, analytical outputs instead of generic LLM responses.
